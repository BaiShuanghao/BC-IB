{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/bcib/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from mpi import load_mpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPI(\n",
       "  (patch2embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
       "  )\n",
       "  (encoder_blocks): ModuleList(\n",
       "    (0-11): 12 x Block(\n",
       "      (pre_norm_attn): RMSNorm()\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (layer_scale_attn): LayerScale()\n",
       "      (pre_norm_mlp): RMSNorm()\n",
       "      (mlp): Sequential(\n",
       "        (0): SwishGLU(\n",
       "          (act): SiLU()\n",
       "          (project): Linear(in_features=384, out_features=3072, bias=True)\n",
       "        )\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      )\n",
       "      (layer_scale_mlp): LayerScale()\n",
       "    )\n",
       "  )\n",
       "  (encoder_norm): RMSNorm()\n",
       "  (temporal_attn): MultiScaleDeformableAttention(\n",
       "    (sampling_offsets): Linear(in_features=384, out_features=48, bias=True)\n",
       "    (attention_weights): Linear(in_features=384, out_features=24, bias=True)\n",
       "    (value_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (output_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "  )\n",
       "  (temporal_attn_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  (token_aggregate): TokenAggregation(\n",
       "    (projection): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (attn_norm): RMSNorm()\n",
       "    (attn): MAPAttention(\n",
       "      (q): Linear(in_features=384, out_features=384, bias=False)\n",
       "      (kv): Linear(in_features=384, out_features=768, bias=False)\n",
       "      (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "    )\n",
       "    (mlp_norm): RMSNorm()\n",
       "    (mlp): Sequential(\n",
       "      (0): SwishGLU(\n",
       "        (act): SiLU()\n",
       "        (project): Linear(in_features=384, out_features=3072, bias=True)\n",
       "      )\n",
       "      (1): Linear(in_features=1536, out_features=384, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder2decoder_vis): Linear(in_features=384, out_features=192, bias=True)\n",
       "  (encoder2decoder_lang): Linear(in_features=384, out_features=192, bias=True)\n",
       "  (encoder2decoder_ctx): Linear(in_features=384, out_features=192, bias=True)\n",
       "  (encoder2decoder_det_query): Linear(in_features=384, out_features=192, bias=True)\n",
       "  (reconstruction_embedding): Embedding(196, 192)\n",
       "  (MotionFormer): ModuleList(\n",
       "    (0-5): 6 x MotionFormerDecoderLayer(\n",
       "      (ca_text): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "      )\n",
       "      (catext_dropout): Identity()\n",
       "      (catext_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (cross_attn_det_motion): BiAttentionBlock(\n",
       "        (layer_norm_v): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_l): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): BiMultiHeadAttention(\n",
       "          (v_proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (l_proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (values_v_proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (values_l_proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (out_v_proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (out_l_proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (attn_cross): MultiScaleDeformableAttention(\n",
       "        (sampling_offsets): Linear(in_features=192, out_features=48, bias=True)\n",
       "        (attention_weights): Linear(in_features=192, out_features=24, bias=True)\n",
       "        (value_proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (output_proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "      )\n",
       "      (dropout_cross): Dropout(p=0.0, inplace=False)\n",
       "      (norm_cross): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_inter): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "      )\n",
       "      (dropout_inter): Dropout(p=0.0, inplace=False)\n",
       "      (norm_inter): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (activation): GELU(approximate='none')\n",
       "      (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      (dropout4): Dropout(p=0.0, inplace=False)\n",
       "      (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "  (reconstruction_prediction): Linear(in_features=192, out_features=768, bias=True)\n",
       "  (bbox_regression): Linear(in_features=384, out_features=4, bias=True)\n",
       "  (bbox_regression_decoder): Linear(in_features=192, out_features=4, bias=True)\n",
       "  (image_projection): Linear(in_features=384, out_features=128, bias=True)\n",
       "  (lang_projection): Linear(in_features=384, out_features=128, bias=True)\n",
       "  (lm): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lang2encoder): Linear(in_features=768, out_features=384, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = \"/root/model/mpi/mpi-small\"\n",
    "language_model_path = \"/root/model/distilbert-base-uncased\"\n",
    "device = \"cuda:0\"\n",
    "model = load_mpi(root_dir, device, freeze=True, language_model_path=language_model_path)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0706, 0.0588, 0.0627,  ..., 0.2039, 0.0863, 0.0667],\n",
      "          [0.0706, 0.0902, 0.0667,  ..., 0.1608, 0.0745, 0.0745],\n",
      "          [0.3725, 0.1922, 0.1020,  ..., 0.0588, 0.0706, 0.0706],\n",
      "          ...,\n",
      "          [0.5255, 0.5216, 0.5176,  ..., 0.7608, 0.7922, 0.8314],\n",
      "          [0.5137, 0.5176, 0.5255,  ..., 0.7569, 0.7882, 0.8235],\n",
      "          [0.5373, 0.5412, 0.5294,  ..., 0.7529, 0.7843, 0.8196]],\n",
      "\n",
      "         [[0.0667, 0.0627, 0.0667,  ..., 0.1961, 0.0784, 0.0588],\n",
      "          [0.0510, 0.0863, 0.0549,  ..., 0.1529, 0.0667, 0.0667],\n",
      "          [0.3294, 0.1490, 0.0667,  ..., 0.0510, 0.0627, 0.0627],\n",
      "          ...,\n",
      "          [0.5255, 0.5216, 0.5176,  ..., 0.8118, 0.8431, 0.8824],\n",
      "          [0.5137, 0.5176, 0.5255,  ..., 0.8078, 0.8392, 0.8745],\n",
      "          [0.5373, 0.5412, 0.5294,  ..., 0.8039, 0.8353, 0.8706]],\n",
      "\n",
      "         [[0.0510, 0.0471, 0.0510,  ..., 0.1922, 0.0745, 0.0549],\n",
      "          [0.0392, 0.0706, 0.0392,  ..., 0.1490, 0.0627, 0.0627],\n",
      "          [0.3137, 0.1333, 0.0510,  ..., 0.0471, 0.0588, 0.0588],\n",
      "          ...,\n",
      "          [0.5255, 0.5216, 0.5176,  ..., 0.7804, 0.8118, 0.8510],\n",
      "          [0.5137, 0.5176, 0.5255,  ..., 0.7765, 0.8078, 0.8431],\n",
      "          [0.5373, 0.5412, 0.5294,  ..., 0.7725, 0.8039, 0.8392]]]])\n",
      "torch.Size([1, 2, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "transforms = T.Compose([T.Resize(256),\n",
    "                        T.CenterCrop(224),\n",
    "                        T.ToTensor()])\n",
    "image = cv2.imread(\"/root/code/BC-IB/third_party/methods/MPI/assets/example_franka_kitchen.jpg\")\n",
    "image = transforms(Image.fromarray(image.astype(np.uint8))).unsqueeze(0)\n",
    "print(image)\n",
    "visual_input = torch.stack((image, image), dim=1) # simply repeat the current observation in downstream downstask\n",
    "visual_input = visual_input.to(device=device)\n",
    "print(visual_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 218, 384]) torch.Size([1, 197, 384])\n"
     ]
    }
   ],
   "source": [
    "lang_input = [\"turn on the knob\", ]\n",
    "embedding_with_lang_tokens = model.get_representations(visual_input, lang_input, with_lang_tokens = True)\n",
    "embedding_without_lang_tokens = model.get_representations(visual_input, None, with_lang_tokens = False)\n",
    "print(embedding_with_lang_tokens.shape, embedding_without_lang_tokens.shape) # (1, 218, 384), (1, 197, 384)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
