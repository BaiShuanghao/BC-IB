defaults:
  - _self_
  - ../base/data@data: default
  - ../base/algo@algo: bc_ib_policy   
  - ../base/policy@policy: mlp_policy    # policy_name: BCMLPPolicy, image encoder: resnet, fuse: mlp
  - ../base/train@train: default
  - ../base/eval@eval: default
  - ../base/env@env: default


# record
experiment: "bc_ib_policy"     # tag for wandb and log dir   
experiment_dir: ???

hydra:
  run:
    dir: ./outputs/libero/${experiment}/mlp/${data.env_name}/ratio${data.train_ratio}_scale${mi_loss_scale}_${mine_mi_loss_scale}/${now:%m%d}_${now:%H%M}_seed${train.seed}
  sweep:
    dir: ./outputs/libero/${experiment}/mlp/${data.env_name}/ratio${data.train_ratio}_scale${mi_loss_scale}_${mine_mi_loss_scale}/${now:%m%d}_${now:%H%M}_seed${train.seed}
    subdir: ${hydra.job.num}
    
wandb:
  use_wandb: true
  project: bc-ib-mlp
  name: ${data.env_name}_${experiment}_mlp_${now:%m%d}_${now:%H%M}_seed${train.seed}_ratio${data.train_ratio}_${hydra:job.num}
  group: ${data.env_name}_${experiment}_mlp
  dir: ./wandb/${env.env_type}/${experiment}/mlp/${data.env_name}/ratio${data.train_ratio}_scale${mi_loss_scale}_${mine_mi_loss_scale}

mi_loss_scale: 0.01
mine_mi_loss_scale: 0.1
